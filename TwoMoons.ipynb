{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Cy4pjeq4v_Y"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5t417C_j4v_e"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDSyNM5r4v_h"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQPQ5bTN4v_l"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugJaUZxn4v_r"
   },
   "source": [
    "# Generate Two Moons Dataset\n",
    "Chapter 18 of Glassner's book describes his datset as follows (note the normalization that occurs):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCdhXqHv4v_t"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1okIsx94v_w"
   },
   "source": [
    "### Define the Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2zqY5Bq4v_x"
   },
   "outputs": [],
   "source": [
    "class TwoMoonsDataset(Dataset):\n",
    "    \"\"\"Two Moons dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, noise=0.08, n_samples=1500):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            noise (float): Amount of noise to use.\n",
    "            n_samples (int): Number of samples to generate.\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        (moons_xy, moons_labels) = make_moons(n_samples=n_samples, noise=noise)\n",
    "        self.sample = preprocessing.scale(moons_xy.astype(float))\n",
    "        self.target = moons_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.sample[idx], np.reshape(self.target[idx],(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2JnRKgb4v_3"
   },
   "outputs": [],
   "source": [
    "def plot_moons(dataset, title):\n",
    "    clr_list = ['#8800FF', '#FF0000']\n",
    "    clrs = [clr_list[v] for v in dataset.target]\n",
    "\n",
    "    plt.scatter(dataset.sample[:,0], dataset.sample[:,1], c=clrs, s=15, linewidths=0.5, edgecolors='k')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')\n",
    "    plt.xticks()\n",
    "    plt.yticks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9d0pvPS4wAD"
   },
   "source": [
    "# Define the Two-Layer Network\n",
    "As noted below, Andrew Glassner includes a bias term in each activation and the network has a total of 37 parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ca7jh7hv4wAE"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50o6bRTE4wAF"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4, bias=True)\n",
    "        self.fc2 = nn.Linear(4, 4, bias=True)\n",
    "        self.fc3 = nn.Linear(4, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    "    \n",
    "    # Return all the activations so we can plot them\n",
    "    def activations(self, x):\n",
    "        l1 = F.relu(self.fc1(x))\n",
    "        l2 = F.relu(self.fc2(l1))\n",
    "        output = torch.sigmoid(self.fc3(l2))\n",
    "        return torch.cat((l1,l2,output), 1)\n",
    "\n",
    "    def size(self):\n",
    "        total_model_size = 0\n",
    "        state_dict = self.state_dict()\n",
    "        for param_tensor in state_dict:\n",
    "            sz = state_dict[param_tensor].size()\n",
    "            total_model_size += np.prod(sz)\n",
    "            \n",
    "        return total_model_size\n",
    "    \n",
    "    def get_weights(self):\n",
    "        state_dict=self.state_dict()\n",
    "        return np.hstack(list(map(lambda param: state_dict[param].flatten(), state_dict)))        \n",
    "        \n",
    "    def print(self):\n",
    "        total_model_size = 0\n",
    "        state_dict = self.state_dict()\n",
    "\n",
    "        print(\"Model's state_dict:\\n\")\n",
    "\n",
    "        # print out size of each set of parameter\n",
    "        for param_tensor in state_dict:\n",
    "            sz = state_dict[param_tensor].size()\n",
    "\n",
    "            # skip empty parameters (like batch normalization history length)\n",
    "            if len(sz) == 0:\n",
    "                continue\n",
    "\n",
    "            total_model_size += np.prod(sz)\n",
    "            if len(sz) > 1:\n",
    "                print('{:16s} {:26s} : {} x {} = {:,}'.format(param_tensor, str(sz), sz[0], np.prod(sz[1:]), np.prod(sz)))\n",
    "            else:\n",
    "                print('{:16s} {:26s} : {:,}'.format(param_tensor, str(sz), np.prod(sz)))\n",
    "            print('{}\\n'.format(state_dict[param_tensor]))\n",
    "\n",
    "        # print out total\n",
    "        print('\\n{:43} : {:,}'.format('Total Model Size',total_model_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Training Class\n",
    "Put in class to encapsulate the model and device instance and hide methods. Maybe just put in module...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkTrainer():\n",
    "    def __init__(self, model, lr, momentum, seed=0, no_cuda=False, mini_batch_log_fn=None):\n",
    "        # Initialize random number generators for determinism\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        \n",
    "        # TODO: pass in network class\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer = optim.SGD(self.model.parameters(), lr, momentum)\n",
    "        \n",
    "        self.mini_batch_log_fn = mini_batch_log_fn\n",
    "        \n",
    "        # Consider moving loss criteria into the network definition so that\n",
    "        # the network defines the cost and the NetworkTrainer defines the optimizer\n",
    "        self.loss_criterion = nn.MSELoss()\n",
    "        \n",
    "        self.epoch = 0\n",
    "        \n",
    "    def _train(self, train_loader):\n",
    "        # Set model to be in training mode\n",
    "        self.model.train()\n",
    "        sample_idx = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data.float())\n",
    "            loss = self.loss_criterion(output, target.float())\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.mini_batch_log_fn is not None:\n",
    "                sample_idx += len(data)\n",
    "                avg_loss = loss.item() / len(data)\n",
    "                self.mini_batch_log_fn(self.epoch, sample_idx, avg_loss,\n",
    "                                       train_loader, self.model, self.device)\n",
    "\n",
    "    def _test(self, test_loader):\n",
    "        # Set model to be in testing mode\n",
    "        self.model.eval()\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data.float())\n",
    "                loss += self.loss_criterion(output, target.float()).item() # sum up batch loss\n",
    "                pred = torch.round(output).long() # Round to 0/1\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss /= len(test_loader.dataset)\n",
    "\n",
    "        return test_loss, correct\n",
    "\n",
    "    def _run_epoch(self, train_loader, test_loader, verbose=False):\n",
    "        if verbose is False:\n",
    "            self._train(train_loader)\n",
    "        else:\n",
    "            train_start = time.perf_counter()\n",
    "            self._train(train_loader)\n",
    "            train_end = time.perf_counter()\n",
    "            train_delta = train_end - train_start\n",
    "            print(\"Training took {:.1f}s.\\n\".format(train_delta))\n",
    "\n",
    "            test_start = time.perf_counter()\n",
    "            loss, correct = _test(test_loader)\n",
    "            test_end = time.perf_counter()\n",
    "            test_delta = test_end - test_start\n",
    "\n",
    "            print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "            print(\"Testing took {:.1f}s.\\n\".format(test_delta))\n",
    "            \n",
    "    def run(self, epochs, train_loader, test_loader, verbose=False):\n",
    "        # Log initial state\n",
    "        if verbose is True:\n",
    "            print(\"Initialized:\")\n",
    "            self.test(test_loader)\n",
    "            print(\"\")\n",
    "\n",
    "        self.mini_batch_log_fn(1, 0, 0, train_loader, self.model, self.device)    \n",
    "\n",
    "        # Run epochs\n",
    "        for self.epoch in range(1, epochs + 1):\n",
    "            self._run_epoch(train_loader, test_loader, verbose)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ytr690-gN3pE"
   },
   "source": [
    "# Create Tiled Gif from Multiple Initializations\n",
    "This code runs a set of rows x cols initializations and saves out a gif for the decision surface every ```args.log_interval``` samples through the training data.\n",
    "\n",
    "Once that finishes, they are read in, concatenated into a tiled image and then saved out as an animated gif of the decision surface as the optimzation progresses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NR_gsmE9MvmE"
   },
   "source": [
    "### Functor to Visualize Cost Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functor is the callback that gets passed into the train function. It runs every ```args.log_interval``` samples. This lets us plot the decision surface periodically during training. The decision surface plotting code was adapted from this scikit example\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pT39Kgg4wAW"
   },
   "outputs": [],
   "source": [
    "class mini_batch_functor:\n",
    "    def __init__(self, seed, weight_count, iteration_count, epochs, verbose=False, mimwriter=None, log_interval=None): \n",
    "        self.images = []\n",
    "        self.verbose = verbose\n",
    "        self.mimwriter = mimwriter\n",
    "        self.seed = seed\n",
    "        self.log_interval = log_interval\n",
    "        self.weight_history = np.zeros((iteration_count, weight_count))\n",
    "        self.weight_history_epochs = np.zeros(iteration_count)\n",
    "        self.iteration = 0\n",
    "    \n",
    "    def __call__(self, epoch, sample_idx, avg_loss, data_loader, model, device):\n",
    "        if (self.log_interval is None or\n",
    "            (sample_idx != len(data_loader.dataset) and\n",
    "             sample_idx % self.log_interval != 0)):\n",
    "            return\n",
    "\n",
    "        sample_total = len(data_loader.dataset)\n",
    "        if self.verbose is True:\n",
    "            print('Train Epoch: {} [{:5}/{} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, sample_idx, sample_total,\n",
    "                100. * sample_idx / sample_total, avg_loss))\n",
    "        \n",
    "        epoch_id = np.round(epoch - 1 + sample_idx/sample_total,2)\n",
    "\n",
    "        # record weights\n",
    "        self.weight_history[self.iteration,:] = model.get_weights()\n",
    "        self.weight_history_epochs[self.iteration] = epoch_id\n",
    "\n",
    "        img = self._plot_activations(data_loader.dataset, model, device, self.seed, epoch_id=epoch_id)\n",
    "        #img = self._plot_decision_surface(data_loader.dataset, model, device, epoch_id=epoch_id)\n",
    "        if self.mimwriter is not None:\n",
    "            self.mimwriter.append_data(img)\n",
    "            \n",
    "        self.iteration += 1\n",
    "        \n",
    "    def _plot_decision_surface(self, dataset, model, device, zoom=1.0, epoch_id=None): \n",
    "        # Get samples\n",
    "        samples = dataset.sample;\n",
    "        X = torch.tensor(samples).float()\n",
    "        X = X.to(device)\n",
    "\n",
    "        # Count number correct\n",
    "        Z = model(X)\n",
    "        pred = torch.round(Z).long() # Round to 0/1\n",
    "        x = torch.tensor(dataset.target)\n",
    "        x = x.to(device)\n",
    "        correct = pred.eq(x.view_as(pred)).sum().item()\n",
    "        total = len(pred)\n",
    "\n",
    "        # Get meshgrid for surface\n",
    "        h = 0.02 * zoom   \n",
    "        x_min, x_max = samples[:, 0].min() - .5, samples[:, 0].max() + .5\n",
    "        y_min, y_max = samples[:, 1].min() - .5, samples[:, 1].max() + .5\n",
    "\n",
    "        scale = (zoom-1)/2.0\n",
    "        x_delta = scale * (x_max - x_min)\n",
    "        x_min -= x_delta\n",
    "        x_max += x_delta\n",
    "        y_delta = scale * (y_max - y_min)\n",
    "        y_min -= y_delta\n",
    "        y_max += y_delta\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "\n",
    "        # Classify each point on the grid\n",
    "        X_grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "        X_grid = X_grid.to(device)\n",
    "\n",
    "        Z_grid = model(X_grid).detach().cpu().numpy()\n",
    "\n",
    "        fig = plt.figure(figsize=(4,4), dpi=64)\n",
    "\n",
    "        # Plot decision surface\n",
    "        canvas = FigureCanvas(fig)\n",
    "        if epoch_id is None:\n",
    "            plt.title('Decision Surface\\n{} Out of {} Correct'.format(correct, total), loc='left')\n",
    "        else:\n",
    "            plt.title('Seed {: >#5} - Epoch {: >#6.2f}\\n{}/{} Correct'.format(self.seed, epoch_id, correct, total))        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        Z_grid = Z_grid.reshape(xx.shape)\n",
    "        cm = plt.cm.RdBu\n",
    "        plt.contourf(xx, yy, Z_grid,\n",
    "                     norm=mpl.colors.Normalize(vmin=0.,vmax=1.),\n",
    "                     cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot samples\n",
    "        X = dataset.sample\n",
    "        y_train=dataset.target\n",
    "        cm_bright = ListedColormap(['#FF0000', '#8800FF'])\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=15, linewidths=0.5,\n",
    "                    c=y_train, norm=mpl.colors.Normalize(vmin=0.,vmax=1.),\n",
    "                    cmap=cm_bright, edgecolors='k')\n",
    "\n",
    "        # Convert figure canvas to an image\n",
    "        canvas.draw()\n",
    "        s, (width, height) = canvas.print_to_buffer()\n",
    "        image = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "        return(image)\n",
    "\n",
    "    def _plot_activations(self, dataset, model, device, seed, epoch_id=None, zoom=1.): \n",
    "        # Get samples\n",
    "        model.eval()\n",
    "        samples = dataset.sample;\n",
    "        X = torch.tensor(samples).float()\n",
    "        X = X.to(device)\n",
    "\n",
    "        # Count number correct\n",
    "        Z = model(X)\n",
    "        pred = torch.round(Z).long() # Round to 0/1\n",
    "        x = torch.tensor(dataset.target)\n",
    "        x = x.to(device)\n",
    "        correct = pred.eq(x.view_as(pred)).sum().item()\n",
    "        total = len(pred)\n",
    "\n",
    "        # Get meshgrid for surface\n",
    "        h = 0.02 * zoom   \n",
    "        x_min, x_max = samples[:, 0].min() - .5, samples[:, 0].max() + .5\n",
    "        y_min, y_max = samples[:, 1].min() - .5, samples[:, 1].max() + .5\n",
    "\n",
    "        scale = (zoom-1)/2.0\n",
    "        x_delta = scale * (x_max - x_min)\n",
    "        x_min -= x_delta\n",
    "        x_max += x_delta\n",
    "        y_delta = scale * (y_max - y_min)\n",
    "        y_min -= y_delta\n",
    "        y_max += y_delta\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "\n",
    "        # Classify each point on the grid\n",
    "        X_grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "        X_grid = X_grid.to(device)\n",
    "\n",
    "        Z_grid = model.activations(X_grid).detach().cpu().numpy()\n",
    "\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(4,4), dpi=64)\n",
    "\n",
    "        gs = GridSpec(5, 6, figure=fig)\n",
    "        ax_11 = fig.add_subplot(gs[0, 0])\n",
    "        ax_12 = fig.add_subplot(gs[1, 0])\n",
    "        ax_13 = fig.add_subplot(gs[2, 0])\n",
    "        ax_14 = fig.add_subplot(gs[3, 0])\n",
    "        ax_21 = fig.add_subplot(gs[0, 1])\n",
    "        ax_22 = fig.add_subplot(gs[1, 1])\n",
    "        ax_23 = fig.add_subplot(gs[2, 1])\n",
    "        ax_24 = fig.add_subplot(gs[3, 1])\n",
    "        ax_out = fig.add_subplot(gs[:-1, 2:])\n",
    "        ax_w = fig.add_subplot(gs[4, :])\n",
    "\n",
    "        if epoch_id is None:\n",
    "            fig.suptitle('Activations and Decision Surface\\n{} Out of {} Correct'.format(correct, total), loc='left')\n",
    "        else:\n",
    "            fig.suptitle('Seed {: >#5} - Epoch {: >#6.2f}\\n{}/{} Correct'.format(seed, epoch_id, correct, total))        \n",
    "\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        # Plot activations and output\n",
    "        for i, ax in enumerate(fig.axes[:-1]):\n",
    "            ax.tick_params(labelbottom=False, labelleft=False, left=False, bottom=False)\n",
    "\n",
    "            Z_grid_i = Z_grid[:,i].reshape(xx.shape)\n",
    "            cm = plt.cm.RdBu\n",
    "            ax.contourf(xx, yy, Z_grid_i,\n",
    "                        norm=mpl.colors.Normalize(vmin=0.,vmax=1.),\n",
    "                        cmap=cm, alpha=.8)\n",
    "\n",
    "            # Plot samples\n",
    "            X = dataset.sample\n",
    "            y_train=dataset.target\n",
    "            cm_bright = ListedColormap(['#FF0000', '#8800FF'])\n",
    "            ax.scatter(X[:, 0], X[:, 1], s=1, linewidths=0.1,\n",
    "                        c=y_train, norm=mpl.colors.Normalize(vmin=0.,vmax=1.),\n",
    "                        cmap=cm_bright, edgecolors='k')\n",
    "\n",
    "        # Plot weights\n",
    "        fig.axes[-1].plot(self.weight_history_epochs[:self.iteration+1], self.weight_history[:self.iteration+1,:])\n",
    "\n",
    "        # Convert figure canvas to an image\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        s, (width, height) = canvas.print_to_buffer()\n",
    "        image = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "        return(image)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_animation(args, train_loader, test_loader):\n",
    "    rand_max = 10000\n",
    "    np.random.seed(args.seed)\n",
    "    rand_offset = np.random.randint(rand_max)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    sample_total = len(train_loader.dataset)\n",
    "\n",
    "    # Dump images seed into a gif\n",
    "    for row in range(args.rows):\n",
    "        for col in range(args.cols):\n",
    "            # Create image sequence for one tile\n",
    "            seed = np.random.randint(rand_max)-rand_offset\n",
    "            print('seeding[{}][{}] = {}'.format(row, col, seed))\n",
    "\n",
    "            gif_filename = 'two_moons_{}_{}.gif'.format(seed, args.epochs)\n",
    "            with imageio.get_writer(gif_filename, mode='I') as writer:\n",
    "                # Create model\n",
    "                model = Net()\n",
    "                \n",
    "                # Create callback\n",
    "                weight_count = model.size()\n",
    "                iteration_count = np.int64(np.ceil(len(train_loader)/args.log_interval))*args.epochs + 1\n",
    "                callback=mini_batch_functor(seed, weight_count,\n",
    "                                            iteration_count, args.epochs, log_interval=args.log_interval,\n",
    "                                            verbose=False, mimwriter=writer)\n",
    "\n",
    "                # Run training\n",
    "                trainer = NetworkTrainer(model, args.lr, args.momentum, seed=seed,\n",
    "                                         no_cuda=args.no_cuda, mini_batch_log_fn=callback)\n",
    "                trainer.run(args.epochs, train_loader, test_loader, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_gifs(args):\n",
    "    rand_max = 10000\n",
    "    np.random.seed(args.seed)\n",
    "    rand_offset = np.random.randint(rand_max)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    sample_total = args.train_size\n",
    "\n",
    "    # Get readers for each seed's gif\n",
    "    mimreaders = []\n",
    "    for row in range(args.rows):\n",
    "        row_readers = []\n",
    "        for col in range(args.cols):\n",
    "            seed = np.random.randint(rand_max)-rand_offset\n",
    "            gif_filename = 'two_moons_{}_{}.gif'.format(seed, args.epochs)\n",
    "            row_readers.append(imageio.get_reader(gif_filename, mode='I'))\n",
    "        mimreaders.append(row_readers)\n",
    "    \n",
    "    # Read images from individual gifs and turn into a tiled gif\n",
    "    gif_filename = 'two_moons_{}x{}_{}.gif'.format(args.rows, args.cols, args.epochs)\n",
    "    with imageio.get_writer(gif_filename, mode='I') as writer:\n",
    "        minibatch_count = np.ceil(sample_total / args.log_interval).astype(int)\n",
    "        for epoch in range(0, args.epochs):\n",
    "            print('processing epoch {}/{}'.format(epoch+1, args.epochs))\n",
    "            \n",
    "            if epoch is args.epochs-1:\n",
    "                minibatch_count += 1\n",
    "            for minibatch in range(minibatch_count):\n",
    "                sample_idx = np.min((sample_total, args.log_interval*minibatch))\n",
    "                epoch_id = np.round(epoch + sample_idx/sample_total,2)\n",
    "\n",
    "                # Read array of images\n",
    "                images = []\n",
    "                for row in range(args.rows):\n",
    "                    img_row = []\n",
    "                    for col in range(args.cols):\n",
    "                        img = mimreaders[row][col].get_next_data()\n",
    "                        img_row.append(img)\n",
    "                    images.append(img_row)\n",
    "                tiled_image = np.vstack(list(map(lambda row: np.hstack(row), images)))\n",
    "                writer.append_data(tiled_image)\n",
    "\n",
    "    return gif_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_jnUbqQ4v_o"
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "class Args:\n",
    "    train_size=1500\n",
    "    test_size=1500\n",
    "    batch_size=1\n",
    "    test_batch_size=1500\n",
    "    lr=0.05\n",
    "    momentum=0.0\n",
    "    no_cuda=False\n",
    "    epochs=20\n",
    "    log_interval=300\n",
    "    rows = 4\n",
    "    cols = 4\n",
    "    seed=0\n",
    "    save_checkpoints=False\n",
    "    load_checkpoint=None #'mnist_012.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = Args\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    \n",
    "    # DataLoaders for train and test data\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TwoMoonsDataset(n_samples=args.train_size, noise=0.08),\n",
    "        batch_size=args.batch_size,\n",
    "        **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        TwoMoonsDataset(n_samples=args.test_size, noise=0.08),\n",
    "        batch_size=args.test_batch_size,\n",
    "        **kwargs)\n",
    "\n",
    "    # Plot the two datasets to make sure they look right\n",
    "    plt.figure(figsize=(8,12), dpi=150)\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plot_moons(train_loader.dataset, 'Training Set')\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plot_moons(test_loader.dataset, 'Test Set')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Network Dimensions and Weights\n",
    "    # We show 37 parameters below, which matches Glassners\n",
    "    Net().print()\n",
    "\n",
    "    write_animation(args, train_loader, test_loader)\n",
    "    filename = tile_gifs(args)\n",
    "    \n",
    "    print(filename)\n",
    "    plt.imshow(imageio.imread(filename))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "TwoMoons.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
