{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GLE3LqD0aeN",
        "colab_type": "text"
      },
      "source": [
        "# MNIST CNN Classifier\n",
        "Adapted from the [mnist_cnn keras example](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) pointed to from the [AWS tutorial on containers](https://aws.amazon.com/getting-started/tutorials/train-deep-learning-model-aws-ec2-containers/):\n",
        "```\n",
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lneUeuMr0aeR",
        "colab_type": "text"
      },
      "source": [
        "Further adapted from Yan LeCunn's top performing MNIST paper:\n",
        "[Regularization of Neural Networks using DropConnect](http://yann.lecun.com/exdb/publis/pdf/wan-icml-13.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "914zXJCc0aeV",
        "colab_type": "text"
      },
      "source": [
        "# Setup libraries and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GEbpdi80aeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import pickle\n",
        "import imageio\n",
        "import os.path\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zip0uHXz0aee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "#from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db9Uccz_0aek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For confusion matrix and 2D embedding\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvcr8qfq0aen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9hbVzMH0aeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fbbc2b62-8ff8-460d-921c-1008af058abd"
      },
      "source": [
        "try:\n",
        "    # Run this cell to mount your Google Drive.\n",
        "    data_path = '/content/drive'\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount(data_path)\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        data_path = os.path.join(data_path, 'My Drive', 'checkpoints')\n",
        "        !mkdir -p \"$data_path\"\n",
        "    except:\n",
        "        print('Couldn\\'t create', data_path)\n",
        "except:\n",
        "    # Just write locally if not in Colaboratory\n",
        "    data_path = './checkpoints'\n",
        "print(data_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/checkpoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl37ApE70aeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Control the resolution of figures plotted below. 200 dpi works well on my macbook\n",
        "plt.rcParams['figure.dpi'] = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8o-Gur10ae0",
        "colab_type": "text"
      },
      "source": [
        "# Network definition\n",
        "Adapted from this portion of the Keras example model\n",
        "```\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "```\n",
        "A few modifications:\n",
        "* I changed the first layer to output 8 channels instead of 32, with the rationale being that a 3x3 kernel only spans 9 DOF. Any channels above 9 would start to become linearly dependent, but the nonlinearity after them might allow them to learn more?\n",
        "* I added batch normalization after the first two convolutional layers because...well...everyone says they are helpful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS8Da-fM0ae1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        # weights = 1x8x3x3 = 72\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        # weights = 8x64x3x3 = 4,608\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.fc1 = nn.Linear(12*12*64, 128)\n",
        "        # weights = 12x12x64x128 = 1,179,648\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        # weights = 128 x 10 = 1280\n",
        "\n",
        "    def forward(self, x):\n",
        "        # layer size 28x28x1 = 784\n",
        "        cl1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        # layer size 26x26x8 = 5,408\n",
        "        # perf = 21,632 outputs x 288 kernel entries = 6,230,016 mul adds\n",
        "        cl2 = F.relu(self.bn2(self.conv2(cl1)))\n",
        "        # layer size 24x24x64 = 36,864\n",
        "        # perf = 36,864 outputs x 589,824 kernel entries = 21,743,271,936 mul adds\n",
        "        mp = F.max_pool2d(cl2, 2, 2)\n",
        "        # layer size 12x12x64 = 9216\n",
        "        mp_d = self.drop1(mp)\n",
        "        # layer size 1x12*12*64 = 9216\n",
        "        fc1 = F.relu(self.fc1(mp_d.view(-1, 12*12*64)))\n",
        "        # layer size 1x128\n",
        "        # perf = 1,179,648 mul adds\n",
        "        fc2 = self.fc2(self.drop2(fc1))\n",
        "        # layer size 1x10\n",
        "        # perf = 1280 mul adds\n",
        "        return F.log_softmax(fc2, dim=1)\n",
        "    \n",
        "    # Output fc1 features\n",
        "    def features(self, x):\n",
        "        # layer size 28x28x1 = 784\n",
        "        cl1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        # layer size 26x26x8 = 5,408\n",
        "        # perf = 21,632 outputs x 288 kernel entries = 6,230,016 mul adds\n",
        "        cl2 = F.relu(self.bn2(self.conv2(cl1)))\n",
        "        # layer size 24x24x64 = 36,864\n",
        "        # perf = 36,864 outputs x 589,824 kernel entries = 21,743,271,936 mul adds\n",
        "        mp = F.max_pool2d(cl2, 2, 2)\n",
        "        # layer size 12x12x64 = 9216\n",
        "        mp_d = self.drop1(mp)\n",
        "        # layer size 1x12*12*64 = 9216\n",
        "        fc1 = F.relu(self.fc1(mp_d.view(-1, 12*12*64)))\n",
        "        # layer size 1x128\n",
        "        # perf = 1,179,648 mul adds\n",
        "        return fc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqTFqMyP0ae3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer:\n",
        "    def __init__(self,\n",
        "                 seed=1,\n",
        "                 no_cuda=False,\n",
        "                 #load_checkpoint=12,\n",
        "                 load_checkpoint=False,\n",
        "                 checkpoint_path='.'):\n",
        "        \n",
        "        self.batch_size=128\n",
        "        self.test_batch_size=1000\n",
        "        \n",
        "        torch.manual_seed(seed)\n",
        "        self.epoch = 0\n",
        "        \n",
        "        use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "        self.kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
        "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "        self.model = Net().to(self.device)\n",
        "        \n",
        "        #self.lr=0.01\n",
        "        #self.momentum=0.5\n",
        "        #self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=self.momentum)\n",
        "        #self.optimizer = optim.Adadelta(self.model.parameters(), lr=self.lr)\n",
        "        self.optimizer = optim.Adam(self.model.parameters())\n",
        "        self.loss_criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.save_checkpoints = True\n",
        "        self.checkpoint_interval = 10\n",
        "            \n",
        "        if load_checkpoint:\n",
        "            self.load_checkpoint(load_checkpoint)\n",
        "            self.test(test_loader)\n",
        "\n",
        "    def set_learning_rate(self, lr):\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr)\n",
        "        \n",
        "    def train(self, train_loader):\n",
        "        # Set model to be in training mode\n",
        "        self.model.train()\n",
        "        \n",
        "        # Accuracy accumulator \n",
        "        correct = 0\n",
        "        total_loss = 0\n",
        "        mini_batch_losses = []\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(data)\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            loss = self.loss_criterion(output, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            mini_batch_losses.append(loss.item())\n",
        "\n",
        "        return total_loss, correct, mini_batch_losses\n",
        "        \n",
        "    def test(self, test_loader):\n",
        "        # Set model to be in testing mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Accuracy accumulator \n",
        "        correct = 0\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "\n",
        "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "                total_loss += self.loss_criterion(output, target).item() # sum up batch loss\n",
        "\n",
        "        return total_loss, correct\n",
        "\n",
        "    def run_epoch(self, train_loader, test_loader):\n",
        "        train_start = time.perf_counter()\n",
        "        train_loss, train_correct, mini_batch_losses = self.train(train_loader)\n",
        "        train_end = time.perf_counter()\n",
        "        train_count = len(train_loader.dataset)\n",
        "        train_delta = train_end - train_start\n",
        "\n",
        "        test_start = time.perf_counter()\n",
        "        test_loss, test_correct = self.test(test_loader)\n",
        "        test_end = time.perf_counter()\n",
        "        test_count = len(test_loader.dataset)\n",
        "        test_delta = test_end - test_start\n",
        "\n",
        "        print('{:5d} | {:5.1f}s, {:4.1f}s | {:6.4f}, {:6.4f} | {:5d}/{:5d} ({:.2f}%), {:4d}/{:4d} ({:5.2f}%)'.format(\n",
        "            self.epoch,\n",
        "            train_delta, test_delta,\n",
        "            train_loss/train_count, test_loss/test_count,\n",
        "            train_correct, train_count, 100. * train_correct / train_count,\n",
        "            test_correct, test_count, 100. * test_correct / test_count))\n",
        "        \n",
        "        self.epoch = self.epoch + 1\n",
        "        \n",
        "        if self.save_checkpoints:\n",
        "            stats = {\"losses\" : mini_batch_losses,\n",
        "                     \"train_count\" : train_count,\n",
        "                     \"train_correct\" : train_correct,\n",
        "                     \"test_count\" : test_count,\n",
        "                     \"test_correct\" : test_correct}\n",
        "            \n",
        "            with open(os.path.join(self.checkpoint_path, 'stats.pkl'), 'ab') as f:\n",
        "                pickle.dump(stats, f)\n",
        "\n",
        "            if self.epoch % self.checkpoint_interval == 0:\n",
        "                self.save_checkpoint(mini_batch_losses)\n",
        "        \n",
        "    def run_schedule(self, train_loader, test_loader, schedule):\n",
        "        for sched in schedule:\n",
        "            print(\"Running for {} epochs with a learning rate of {}\".format(sched[\"epochs\"], sched[\"lr\"]))\n",
        "            self.set_learning_rate(sched[\"lr\"])\n",
        "            self.run(train_loader, test_loader, epochs = sched[\"epochs\"])\n",
        "            print(\"\")\n",
        "            \n",
        "    def run(self, train_loader, test_loader, epochs=False):\n",
        "        \n",
        "        if not epochs:\n",
        "            epochs = self.epochs\n",
        "\n",
        "        print('Epoch | Time          | Loss           | Accuracy')\n",
        "        print('      | Train,  Test  | Train,  Test   | Train,                Test')\n",
        "        for epoch in range(epochs):\n",
        "            self.run_epoch(train_loader, test_loader)\n",
        "    \n",
        "    def save_checkpoint(self, losses=[], prefix='mnist_'):\n",
        "        checkpoint = {'epoch' : self.epoch,\n",
        "                      'losses' : losses,\n",
        "                      'model_state_dict': self.model.state_dict(),\n",
        "                      'optimizer_state_dict' : self.optimizer.state_dict(),\n",
        "                      'loss_criterion' : self.loss_criterion}\n",
        "        torch.save(checkpoint, os.path.join(self.checkpoint_path, '{}{:03}.pth'.format(prefix, self.epoch)))\n",
        "\n",
        "    def load_checkpoint(self, epoch, prefix='mnist_'):\n",
        "        checkpoint = torch.load(os.path.join(self.checkpoint_path, '{}{:03}.pth'.format(prefix, epoch)))\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.loss_criterion = checkpoint['loss_criterion']\n",
        "        for parameter in self.model.parameters():\n",
        "            parameter.requires_grad = False\n",
        "        return checkpoint['losses']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01nzfd5f0ae_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(checkpoint_path=data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reDVFlzA0afC",
        "colab_type": "text"
      },
      "source": [
        "## Network Graph Plotting\n",
        "These are the graph of functions back propagated through during the call to backward. This is adapted from the [PyTorch tutorial documentation](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEbHHvZ-0afD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# depth-first search through the back prop functions\n",
        "def print_graph(fn, depth=0):\n",
        "    if fn is None:\n",
        "        return\n",
        "\n",
        "    print('|'*depth, type(fn).__name__)\n",
        "    for i in range(len(fn.next_functions)):\n",
        "        print_graph(fn.next_functions[i][0], depth+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwd6Nnx00afH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "5569356b-4ae4-4f1c-a0f1-0f1b44f2daae"
      },
      "source": [
        "# Generate a random input and run it forward\n",
        "batch_size = 1\n",
        "input = torch.randn(batch_size,1,28,28).to(opt.device)\n",
        "output = opt.model(input)\n",
        "\n",
        "# Run the backward pass, which generates the graph\n",
        "opt.model.zero_grad()\n",
        "output.backward(torch.randn(batch_size,10).to(opt.device))\n",
        "\n",
        "# Print the graph\n",
        "print_graph(output.grad_fn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " LogSoftmaxBackward\n",
            "| AddmmBackward\n",
            "|| AccumulateGrad\n",
            "|| FusedDropoutBackward\n",
            "||| ReluBackward0\n",
            "|||| AddmmBackward\n",
            "||||| AccumulateGrad\n",
            "||||| ViewBackward\n",
            "|||||| FusedDropoutBackward\n",
            "||||||| MaxPool2DWithIndicesBackward\n",
            "|||||||| ReluBackward0\n",
            "||||||||| CudnnBatchNormBackward\n",
            "|||||||||| CudnnConvolutionBackward\n",
            "||||||||||| ReluBackward0\n",
            "|||||||||||| CudnnBatchNormBackward\n",
            "||||||||||||| CudnnConvolutionBackward\n",
            "|||||||||||||| AccumulateGrad\n",
            "|||||||||||||| AccumulateGrad\n",
            "||||||||||||| AccumulateGrad\n",
            "||||||||||||| AccumulateGrad\n",
            "||||||||||| AccumulateGrad\n",
            "||||||||||| AccumulateGrad\n",
            "|||||||||| AccumulateGrad\n",
            "|||||||||| AccumulateGrad\n",
            "||||| TBackward\n",
            "|||||| AccumulateGrad\n",
            "|| TBackward\n",
            "||| AccumulateGrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxrZIw1G0afI",
        "colab_type": "text"
      },
      "source": [
        "## Print Model Parameter Sizes\n",
        "How many weights/parameters are there in each expression (portion of a layer) that contribute to the gradient?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF3hoKcM0afJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_model_size(model):\n",
        "    total_model_size = 0\n",
        "    print(\"Model's state_dict:\")\n",
        "    # print out size of each set of parameter\n",
        "    for param_tensor in model.state_dict():\n",
        "        sz = model.state_dict()[param_tensor].size()\n",
        "\n",
        "        # skip empty parameters (like batch normalization history length)\n",
        "        if len(sz) == 0:\n",
        "            continue\n",
        "\n",
        "        total_model_size += np.prod(sz)\n",
        "        if len(sz) > 1:\n",
        "            print('{:16s} {:26s} : {} x {} = {:,}'.format(param_tensor, str(sz), sz[0], np.prod(sz[1:]), np.prod(sz)))\n",
        "        else:\n",
        "            print('{:16s} {:26s} : {:,}'.format(param_tensor, str(sz), np.prod(sz)))\n",
        "\n",
        "    # print out total\n",
        "    print('\\n{:43} : {:,}'.format('Total Model Size',total_model_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OKoYjpi70afK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "434fa687-7ca1-4ee2-8bd7-012e63105f81"
      },
      "source": [
        " print_model_size(opt.model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight     torch.Size([32, 1, 3, 3])  : 32 x 9 = 288\n",
            "conv1.bias       torch.Size([32])           : 32\n",
            "bn1.weight       torch.Size([32])           : 32\n",
            "bn1.bias         torch.Size([32])           : 32\n",
            "bn1.running_mean torch.Size([32])           : 32\n",
            "bn1.running_var  torch.Size([32])           : 32\n",
            "conv2.weight     torch.Size([64, 32, 3, 3]) : 64 x 288 = 18,432\n",
            "conv2.bias       torch.Size([64])           : 64\n",
            "bn2.weight       torch.Size([64])           : 64\n",
            "bn2.bias         torch.Size([64])           : 64\n",
            "bn2.running_mean torch.Size([64])           : 64\n",
            "bn2.running_var  torch.Size([64])           : 64\n",
            "fc1.weight       torch.Size([128, 9216])    : 128 x 9216 = 1,179,648\n",
            "fc1.bias         torch.Size([128])          : 128\n",
            "fc2.weight       torch.Size([10, 128])      : 10 x 128 = 1,280\n",
            "fc2.bias         torch.Size([10])           : 10\n",
            "\n",
            "Total Model Size                            : 1,200,266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vw8yxg-0afM",
        "colab_type": "text"
      },
      "source": [
        "# DataLoaders|\n",
        "Wrap dataset downloaders in a DataLoader class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCwZ5fRS0afN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "f0d92ad0-de96-4477-95f1-152638672b71"
      },
      "source": [
        "# DataLoaders for train and test data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.RandomAffine(15,translate=(0.1,0.1),scale=(0.9,1.1),shear=None,resample=PIL.Image.BILINEAR),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=opt.batch_size, shuffle=True, **opt.kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=opt.test_batch_size, **opt.kwargs)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 7440182.22it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 334608.14it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 4500004.31it/s]                            \n",
            "8192it [00:00, 124949.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ScxfTzL0afO",
        "colab_type": "text"
      },
      "source": [
        "# Train (or load) the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rq1yyuL0afO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ca221324-5502-4486-d792-d46d8a80c17d"
      },
      "source": [
        "schedule = [\n",
        "    {\"epochs\" : 200, \"lr\" : 1e-3},\n",
        "    {\"epochs\" : 200, \"lr\" : 5e-4},\n",
        "    {\"epochs\" : 200, \"lr\" : 1e-4},\n",
        "    {\"epochs\" : 200, \"lr\" : 5e-5},\n",
        "    {\"epochs\" : 200, \"lr\" : 1e-5}]\n",
        "opt.run_schedule(train_loader, test_loader, schedule)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running for 1 epochs with a learning rate of 0.001\n",
            "Epoch | Time          | Loss           | Accuracy\n",
            "      | Train,  Test  | Train,  Test   | Train,                Test\n",
            "    0 |  14.9s,  1.4s | 0.4927, 0.0610 | 50581/60000 (84.30%), 9812/10000 (98.12%)\n",
            "\n",
            "Running for 1 epochs with a learning rate of 0.0005\n",
            "Epoch | Time          | Loss           | Accuracy\n",
            "      | Train,  Test  | Train,  Test   | Train,                Test\n",
            "    1 |  15.6s,  1.4s | 0.2343, 0.0397 | 55754/60000 (92.92%), 9878/10000 (98.78%)\n",
            "\n",
            "Running for 1 epochs with a learning rate of 0.0001\n",
            "Epoch | Time          | Loss           | Accuracy\n",
            "      | Train,  Test  | Train,  Test   | Train,                Test\n",
            "    2 |  15.6s,  1.4s | 0.1903, 0.0332 | 56507/60000 (94.18%), 9893/10000 (98.93%)\n",
            "\n",
            "Running for 1 epochs with a learning rate of 5e-05\n",
            "Epoch | Time          | Loss           | Accuracy\n",
            "      | Train,  Test  | Train,  Test   | Train,                Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2P1uKt3UVDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "fccee027-399b-42e4-81e0-b620aa8f0f3e"
      },
      "source": [
        "opt.set_optimizer(1e-4)\n",
        "opt.run(train_loader, test_loader, epochs=500)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cd07257974ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Optimizer' object has no attribute 'set_optimizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-SOg8s0afQ",
        "colab_type": "text"
      },
      "source": [
        "# Visualization Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCRKD4-o0afR",
        "colab_type": "text"
      },
      "source": [
        "## Create a 2800 x 2800 tiled image from the 10,000 test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajyf9s0w0afS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tile_digits(digits, outputs=None, shape='Square', train=False):\n",
        "    ds = datasets.MNIST('../data', train=train, transform=transforms.Compose([\n",
        "                           transforms.ToTensor()]))\n",
        "\n",
        "    cmap = mpl.cm.jet\n",
        "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
        "    cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, N=10)\n",
        "    \n",
        "    def get_img(idx):\n",
        "        if idx >= len(digits) or idx < 0 or digits[idx] < -10:\n",
        "            return np.zeros((28,28,3)).astype('uint8')\n",
        "        \n",
        "        idx = digits[idx]\n",
        "        if idx < 0:\n",
        "            clr = cmap(-idx-1)\n",
        "            img = np.full((28,28,1), 255)\n",
        "        else:\n",
        "            clr = cmap(ds[idx][1])\n",
        "            img = ds[idx][0].numpy().reshape(28,28)*255\n",
        "            \n",
        "        return np.dstack([(img*clr[c]).astype('uint8') for c in range(3)])\n",
        "\n",
        "    def get_target(idx):\n",
        "        if idx >= len(digits) or idx < 0 or digits[idx] < 0:\n",
        "            return -1\n",
        "        return ds[digits[idx]][1]\n",
        "\n",
        "    def get_class(idx):\n",
        "        if idx >= len(digits) or idx < 0 or digits[idx] < 0:\n",
        "            return -1\n",
        "        return outputs[digits[idx]].argmax(dim=0, keepdim=True).numpy().T[0]\n",
        "\n",
        "    cnt = len(digits)\n",
        "    if shape is 'Square':\n",
        "        cols = np.ceil(np.sqrt(cnt)).astype('int64')\n",
        "    elif shape is 'Horizontal':\n",
        "        cols = cnt\n",
        "    else:\n",
        "        cols = 1\n",
        "\n",
        "    img = np.vstack([np.hstack([get_img(off+col) for col in range(cols)]) for off in range(0, cnt, cols)])\n",
        "    targets = np.vstack([np.hstack([get_target(off+col) for col in range(cols)]) for off in range(0, cnt, cols)])\n",
        "    if outputs is None:\n",
        "        return img, targets\n",
        "    else:\n",
        "        classes = np.vstack([np.hstack([get_class(off+col) for col in range(cols)]) for off in range(0, cnt, cols)])\n",
        "\n",
        "    return img, targets, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fevtqtgo0afT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tiled, target = tile_digits(range(10000))\n",
        "imageio.imwrite('tiled.png', tiled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pp3ID-00afW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax=plt.subplots(figsize=(5,5), dpi=200)\n",
        "ax.axis('off')\n",
        "plt.imshow(tiled)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFqiLBir0afY",
        "colab_type": "text"
      },
      "source": [
        "## Inspect Failures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl6ftgY70afY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_failures(model, device, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    batch_offset = 0\n",
        "    failure_indices = []\n",
        "    target_all = torch.zeros((0),dtype=torch.long).to(device)\n",
        "    output_all = torch.zeros((0,10)).to(device)\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            target_all = torch.cat((target_all, target))\n",
        "            output_all = torch.cat((output_all, output))\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            idx = np.where(pred.ne(target.view_as(pred)).to(torch.device(\"cpu\")))[0]\n",
        "            failure_indices += list(idx + batch_offset)\n",
        "            \n",
        "            batch_offset += pred.size(0)\n",
        "    return np.array(failure_indices), output_all, target_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8gbwV8f0afa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "failure_indices, output_all, target_all = get_failures(opt.model, opt.device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BXQ9Au-A0afb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_failures = target_all[failure_indices]\n",
        "failure_idx_by_digit = list(map(lambda digit: np.where(target_failures.eq(digit).to(torch.device(\"cpu\")))[0], range(0,10)))\n",
        "\n",
        "# Print sorted failures\n",
        "sorted_failures = np.hstack(failure_idx_by_digit)\n",
        "fail_img, targets, classes = tile_digits(failure_indices[sorted_failures], output_all.to(torch.device(\"cpu\")))\n",
        "\n",
        "print(len(failure_indices))\n",
        "print('Classifications:\\n', classes)\n",
        "imageio.imwrite('sorted_failures.png', fail_img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYYtuSQt0afc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax=plt.subplots(figsize=(5,5), dpi=200)\n",
        "ax.axis('off')\n",
        "plt.imshow(fail_img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWPYEc-0afd",
        "colab_type": "text"
      },
      "source": [
        "## Plot t-SNE embedding of fc1 features\n",
        "First extract the fc1 features for each test image and their ground truth values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZVSRkR50afd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fc1_features(model, device, dataloader):\n",
        "    # Set model to be in testing mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = list(map(lambda x: (model.features(x[0].to(device)), x[1].to(device)), dataloader))\n",
        "        fc1 = torch.cat(list(map(lambda x: x[0].to(torch.device(\"cpu\")), x))).detach().numpy()\n",
        "        target = torch.cat(list(map(lambda x: x[1].to(torch.device(\"cpu\")), x))).detach().numpy()\n",
        "        return fc1, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiaKKFhe0afg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc1, target=get_fc1_features(opt.model, opt.device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apc9jXVO0afi",
        "colab_type": "text"
      },
      "source": [
        "Embed the 128 dimensional fc1 features in 2D space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMKQ6FI40afj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_embedded = TSNE(n_components=2).fit_transform(fc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlIRQhBE0afk",
        "colab_type": "text"
      },
      "source": [
        "Plot the 2D embedding, color-coded by the ground truth value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw0OUpDv0afk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmap = mpl.cm.jet\n",
        "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
        "cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, N=10)\n",
        "\n",
        "#def onclick(event):\n",
        "#    print('%s click: button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
        "#          ('double' if event.dblclick else 'single', event.button,\n",
        "#           event.x, event.y, event.xdata, event.ydata))\n",
        "\n",
        "fig, (ax0) = plt.subplots(1,1, figsize=(6,5), dpi=200)\n",
        "\n",
        "#cid = fig.canvas.mpl_connect('button_release_event', onclick)\n",
        "\n",
        "cs=ax0.scatter(X_embedded[:,0], X_embedded[:,1],\n",
        "               norm=mpl.colors.Normalize(vmin=-0.5, vmax=9.5),\n",
        "               s=.5, c=target, cmap=cmap)\n",
        "\n",
        "cb = plt.colorbar(cs, ax=ax0)\n",
        "cb.set_ticks(np.arange(0,10))\n",
        "cb.set_ticklabels(np.arange(0, 10))\n",
        "\n",
        "ax0.set_xticks([])\n",
        "ax0.set_yticks([])\n",
        "\n",
        "\n",
        "#ax[1].set_xticks([])\n",
        "#ax[1].set_yticks([])\n",
        "\n",
        "\n",
        "len(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4FF8LU60afl",
        "colab_type": "text"
      },
      "source": [
        "### How about just 4, 7 and 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xehv-4ri0afl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lst = [4,7,9]\n",
        "fc1_sub=fc1[np.isin(target,lst),:]\n",
        "target_sub=target[np.isin(target,lst)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9DGu2CW0afp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_embedded_sub = TSNE(n_components=2).fit_transform(fc1_sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDs6KH8v0afq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax0) = plt.subplots(1,1, figsize=(6,5), dpi=200)\n",
        "\n",
        "cmap = mpl.cm.jet\n",
        "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
        "cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, N=10)\n",
        "\n",
        "cs=plt.scatter(X_embedded_sub[:,0], X_embedded_sub[:,1], s=.5, c=target_sub, cmap=cmap, norm=mpl.colors.Normalize(vmin=-0.5, vmax=9.5))\n",
        "cb = plt.colorbar(cs)\n",
        "cb.set_ticks(np.arange(0,10))\n",
        "cb.set_ticklabels(np.arange(0, 10))\n",
        "\n",
        "ax0.set_xticks([])\n",
        "ax0.set_yticks([])\n",
        "len(target_sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPOAH86q0afr",
        "colab_type": "text"
      },
      "source": [
        "## What are the Nearest Neighbors for Failures?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTtRxRa-0afr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataLoaders for train and test data\n",
        "train_loader_fc1 = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=opt.batch_size, shuffle=False, **opt.kwargs)\n",
        "\n",
        "train_fc1, train_target=get_fc1_features(opt.model, opt.device, train_loader_fc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlSlgqR40afs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nbrs = NearestNeighbors(n_neighbors=16, algorithm='ball_tree').fit(train_fc1)\n",
        "distances, indices = nbrs.kneighbors(fc1[failure_indices[sorted_failures],:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKmuqgu50afs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt = len(sorted_failures)\n",
        "\n",
        "failure_classes = output_all[failure_indices[sorted_failures]].argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "\n",
        "failure_img = tile_digits(failure_indices[sorted_failures], shape='Vertical')[0]\n",
        "failure_classification_img = tile_digits((-failure_classes.to(torch.device(\"cpu\")).numpy()-1).transpose()[0], shape='Vertical')[0]\n",
        "neigh_img = np.vstack([tile_digits(indices[idx,:], shape='Horizontal', train=True)[0] for idx in range(cnt)])\n",
        "\n",
        "imageio.imwrite('neighbors_train.png', np.hstack([failure_img, failure_classification_img, neigh_img]))\n",
        "\n",
        "fig, ax=plt.subplots(figsize=(5,5), dpi=200)\n",
        "ax.axis('off')\n",
        "ax.imshow(np.hstack([failure_img, failure_classification_img, neigh_img]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW2GawFu0aft",
        "colab_type": "text"
      },
      "source": [
        "## Plot Confusion Matrix\n",
        "The confusion matrix plotting function was copied from [Yassine Ghouzam's great notebook](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8FzGZDi0aft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4rOYyMp0afu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_all = output_all.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(target_all.to(torch.device(\"cpu\")), pred_all.to(torch.device(\"cpu\"))) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJDZrpgG0afv",
        "colab_type": "text"
      },
      "source": [
        "## Look at weights/kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1durWeN0afv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_kernels(conv_layer):\n",
        "    out_dim = conv_layer.size()[0]\n",
        "    in_dim = conv_layer.size()[1]\n",
        "    kw = conv_layer.size()[2]\n",
        "    kh = conv_layer.size()[3]\n",
        "    #np.linalg.svd()\n",
        "\n",
        "    for row in range(0,out_dim):\n",
        "        fig, ax = plt.subplots(1, in_dim)\n",
        "        for col in range(0,in_dim):\n",
        "            if in_dim>1:\n",
        "                col_ax = ax[col]\n",
        "            else:\n",
        "                col_ax = ax\n",
        "            col_ax.imshow(conv_layer[row][col].numpy(), cmap='binary')\n",
        "            col_ax.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2J3VJE0afw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_kernels(opt.model.state_dict()['conv1.weight'].permute(1,0,2,3).to(torch.device(\"cpu\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WVCBLhJv0afy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_kernels(opt.model.state_dict()['conv2.weight'].to(torch.device(\"cpu\")))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}